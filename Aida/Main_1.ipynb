{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf8zksoawaHq"
   },
   "source": [
    "# ML: Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data split:\n",
    "    - Data is split into **train (90%)** and **test (10%)**\n",
    "    - Train data is used for cross-validation as well when performing hyperparameter tuning \n",
    "- Null/empty values:\n",
    "    - Used **SimpleImputer**:\n",
    "        - numerical columns: **mean**\n",
    "        - categorical columns: **most_frequent**\n",
    "- Encoding:\n",
    "    - y data: **LabelEncoder**\n",
    "    - x data: **TargetEncoder**\n",
    "- Feature selection:\n",
    "    - Used **RandomForestClassifier** and **SelectFromModel** to select the needed features \n",
    "    - Removed features from x_train data\n",
    "- Model training:\n",
    "    - Used **XGBClassifier** as it was stated in multiple papers for yielding the best results \n",
    "    - Used **f1_macro** for scoring \n",
    "    - Fit using **train** data\n",
    "- Testing:\n",
    "    - Pre-processing done:\n",
    "        - Handle null/empty values similar to the handling of the train data\n",
    "        - Encode the test data \n",
    "        - Remove feature from **x_test** similar to the ones removed from the **x_train**\n",
    "    - Generate predictions\n",
    "    - Display the following metrics:\n",
    "        - Accuracy \n",
    "        - Precision \n",
    "        - Recall \n",
    "        - F1 Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (1.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (0.14.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
      "Requirement already satisfied: six in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aidaf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\aidaf\\\\OneDrive\\\\Documents\\\\University\\\\Spring 2023-2024\\\\CMPS 396V Machine Learning\\\\Project\\\\ML_Breast_Cancer\\\\Aida\\\\\"\n",
    "# path = \"D:\\\\Desktop\\\\ML\\\\Project\\\\ML_Breast_Cancer\\\\Models\\\\\"\n",
    "\n",
    "def saveModel(fileName, model):\n",
    "  with open(path + fileName, 'wb') as f:\n",
    "      pickle.dump(model, f)\n",
    "\n",
    "def getModel(fileName):\n",
    "  with open(path + fileName, 'rb') as f:\n",
    "      loaded_model = pickle.load(f)\n",
    "  return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tg2D2bbw0c5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidaf\\AppData\\Local\\Temp\\ipykernel_1732\\2955086971.py:1: DtypeWarning: Columns (662,664,676,677,683,685,686,687) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data.csv\", encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "y = data[\"cancer_type\"]\n",
    "x = data.drop(columns = [\"cancer_type\", \"patient_id\"])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Null/Empty Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_columns(df):\n",
    "    return list(df.select_dtypes(include=['object', 'category']).columns)\n",
    "def get_numerical_columns(df):\n",
    "    return list(df.select_dtypes(include=['number']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1346, 686)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = get_categorical_columns(x_train)\n",
    "numerical_columns = get_numerical_columns(x_train)\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy='mean') \n",
    "x_train[numerical_columns] = numerical_imputer.fit_transform(x_train[numerical_columns])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')  \n",
    "x_train[categorical_columns] = categorical_imputer.fit_transform(x_train[categorical_columns])\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2amSQIinWRym"
   },
   "outputs": [],
   "source": [
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "x_train = encoder.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Threshold: 1.25*mean\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(rf_classifier)),\n",
    "    ('classification', rf_classifier)\n",
    "])\n",
    "\n",
    "param_grid = {'feature_selection__threshold': ['mean', 'median', '1.25*mean']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "print(\"Selected Features Threshold:\", best_pipeline.named_steps['feature_selection'].threshold)\n",
    "\n",
    "selected_features_mask = best_pipeline.named_steps['feature_selection'].get_support()\n",
    "x_train = x_train.iloc[:, selected_features_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.6179617328464837\n",
      "Best Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Cross-Validation Score:\", best_score)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "saveModel('best_xgb_model.pkl', best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Null/Empty Values of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = get_categorical_columns(x_test)\n",
    "numerical_columns = get_numerical_columns(x_test)\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy='mean') \n",
    "x_test[numerical_columns] = numerical_imputer.fit_transform(x_test[numerical_columns])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent') \n",
    "x_test[categorical_columns] = categorical_imputer.fit_transform(x_test[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Encoding to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "x_test = encoder.fit_transform(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Feature Selection on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.iloc[:, selected_features_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Display Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8666666666666667\n",
      "precision = 0.8140497967479675\n",
      "recall = 0.630031779661017\n",
      "f1-score = 0.6908500904351527\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_pred)\n",
    "precision = precision_score(y_test, test_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, test_pred, average=\"macro\")\n",
    "f1 = f1_score(y_test, test_pred, average=\"macro\")\n",
    "\n",
    "print(\"accuracy =\", accuracy)\n",
    "print(\"precision =\", precision)\n",
    "print(\"recall =\", recall)\n",
    "print(\"f1-score =\", f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
