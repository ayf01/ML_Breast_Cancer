{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf8zksoawaHq"
   },
   "source": [
    "# ML: Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data split:\n",
    "    - Data is split into **train (90%)** and **test (10%)**\n",
    "    - Train data is used for cross-validation as well when performing hyperparameter tuning \n",
    "- Encoding:\n",
    "    - y data: **LabelEncoder**\n",
    "    - x data: **TargetEncoder**\n",
    "- Null/empty values:\n",
    "    - Used **KNNImputer**:\n",
    "        - predicts the value of a data point by averaging the values of its k nearest neighbors based on Euclidean distance metric.\n",
    "        - number of neighbors is set to 2 \n",
    "- Model training:\n",
    "    - Used **XGBClassifier** as it was stated in multiple papers for yielding the best results \n",
    "    - Used **f1_macro** for scoring \n",
    "    - Fit using **train** data\n",
    "- Testing:\n",
    "    - Pre-processing applied:\n",
    "        - Handle null/empty values similar to the handling of the train data\n",
    "        - Encode the test data \n",
    "        - Remove the features removed from **x_train** from **x_test** \n",
    "    - Generate predictions\n",
    "    - Display the following metrics:\n",
    "        - Accuracy \n",
    "        - Precision \n",
    "        - Recall \n",
    "        - F1 Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Pre-requisites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    function to plot learning curve\n",
    "'''\n",
    "def plot_learning_curves(model, x_train, y_train):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model, x_train, y_train, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, val_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "#################################################################################################\n",
    "'''\n",
    "    functions to save model and retrieve model\n",
    "'''\n",
    "path = \"Models\\\\\"\n",
    "def saveModel(fileName, model):\n",
    "  with open(path + fileName, 'wb') as f:\n",
    "      pickle.dump(model, f)\n",
    "\n",
    "def getModel(fileName):\n",
    "  with open(path + fileName, 'rb') as f:\n",
    "      loaded_model = pickle.load(f)\n",
    "  return loaded_model\n",
    "\n",
    "results = [] # Array used to store tuples of (model, accuracy_score)\n",
    "#################################################################################################\n",
    "'''\n",
    "    function to split data\n",
    "'''\n",
    "def train_val_test_split(x, y):\n",
    "    # Splitting into training (80%) and temporary set (20%)\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=3)\n",
    "    # Splitting the temporary set into validation (50%) and test (50%)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, shuffle=True, random_state=3)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "#################################################################################################\n",
    "'''\n",
    "    function to find the distribution of null values in the dataset\n",
    "'''\n",
    "# credit: https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction. \n",
    "def missing_values_table(df):\n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "\n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "    mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    # Print some summary information\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "    \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "        \" columns that have missing values.\")\n",
    "\n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxFKBF_4xByj"
   },
   "source": [
    "## Part 1: Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7PmButs0TOj"
   },
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tg2D2bbw0c5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_16156\\3240169054.py:1: DtypeWarning: Columns (662,664,676,677,683,685,686,687) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data.csv\", encoding=\"utf-8\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>cellularity</th>\n",
       "      <th>chemotherapy</th>\n",
       "      <th>pam50_+_claudin-low_subtype</th>\n",
       "      <th>cohort</th>\n",
       "      <th>er_status_measured_by_ihc</th>\n",
       "      <th>er_status</th>\n",
       "      <th>neoplasm_histologic_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>mtap_mut</th>\n",
       "      <th>ppp2cb_mut</th>\n",
       "      <th>smarcd1_mut</th>\n",
       "      <th>nras_mut</th>\n",
       "      <th>ndfip1_mut</th>\n",
       "      <th>hras_mut</th>\n",
       "      <th>prps2_mut</th>\n",
       "      <th>smarcb1_mut</th>\n",
       "      <th>stmn2_mut</th>\n",
       "      <th>siah1_mut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>474</td>\n",
       "      <td>54.29</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>7029</td>\n",
       "      <td>43.45</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "      <td>4</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>5215</td>\n",
       "      <td>74.11</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>LumB</td>\n",
       "      <td>3</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>5412</td>\n",
       "      <td>51.87</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "      <td>3</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>465</td>\n",
       "      <td>87.18</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 688 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cancer_type  patient_id  age_at_diagnosis cellularity  \\\n",
       "0  Breast Invasive Ductal Carcinoma         474             54.29        High   \n",
       "1  Breast Invasive Ductal Carcinoma        7029             43.45    Moderate   \n",
       "2  Breast Invasive Ductal Carcinoma        5215             74.11        High   \n",
       "3  Breast Invasive Ductal Carcinoma        5412             51.87        High   \n",
       "4  Breast Invasive Ductal Carcinoma         465             87.18    Moderate   \n",
       "\n",
       "   chemotherapy pam50_+_claudin-low_subtype  cohort er_status_measured_by_ihc  \\\n",
       "0             1                        LumB       1                   Positve   \n",
       "1             0                        LumA       4                   Positve   \n",
       "2             0                        LumB       3                   Positve   \n",
       "3             0                        LumA       3                   Positve   \n",
       "4             0                        LumB       1                   Positve   \n",
       "\n",
       "  er_status  neoplasm_histologic_grade  ... mtap_mut ppp2cb_mut  smarcd1_mut  \\\n",
       "0  Positive                        3.0  ...        0          0            0   \n",
       "1  Positive                        1.0  ...        0          0            0   \n",
       "2  Positive                        3.0  ...        0          0            0   \n",
       "3  Positive                        2.0  ...        0          0            0   \n",
       "4  Positive                        3.0  ...        0          0            0   \n",
       "\n",
       "  nras_mut ndfip1_mut  hras_mut  prps2_mut  smarcb1_mut  stmn2_mut  siah1_mut  \n",
       "0        0          0         0          0            0          0          0  \n",
       "1        0          0         0          0            0          0          0  \n",
       "2        0          0         0          0            0          0          0  \n",
       "3        0          0         0          0            0          0          0  \n",
       "4        0          0         0          0            0          0          0  \n",
       "\n",
       "[5 rows x 688 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1496, 688)\n",
      "1199\n",
      "114\n",
      "165\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[data['cancer_type'] == \"Breast Invasive Ductal Carcinoma\"].shape[0])\n",
    "print(data[data['cancer_type'] == \"Breast Invasive Lobular Carcinoma\"].shape[0])\n",
    "print(data[data['cancer_type'] == \"Breast Mixed Ductal and Lobular Carcinoma\"].shape[0])\n",
    "print(data[data['cancer_type'] == \"Breast Invasive Mixed Mucinous Carcinoma\"].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↪ Our dataset is imbalanced\n",
    "- we cannot undersample due to the fact that our dataset is mall\n",
    "- random oversampling may lead to overfitting\n",
    "- there are other techniques for oversamplign (**SMOTE**)\n",
    "- setting class weights in an inversely prop way to its freq.\n",
    "- **boosting** and **bagging** models, **random forest** model are good options.\n",
    "- use **f1-score** or any metric that is sensitive to data imbalance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into features (x) and label (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data and dropping unnecessary features\n",
    "y = data[\"cancer_type\"]\n",
    "x = data.drop(columns = [\"cancer_type\",\"patient_id\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encoding(x, y):\n",
    "    ordinal_features = ['cellularity','3-gene_classifier_subtype','death_from_cancer','pam50_+_claudin-low_subtype','her2_status_measured_by_snp6']# should add the genetic mutation cols too\n",
    "    nominal_features = ['er_status_measured_by_ihc','er_status','her2_status','inferred_menopausal_state','primary_tumor_laterality','pr_status']\n",
    "\n",
    "    x[ordinal_features] = x[ordinal_features].apply(LabelEncoder().fit_transform)\n",
    "    x[nominal_features] = x[nominal_features].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "    genomic_col = x.columns[513:] # genetic mutations\n",
    "    for col in genomic_col:\n",
    "        x.loc[x[col] != '0', col] = 1\n",
    "        x.loc[x[col] == '0', col] = 0\n",
    "        x[col] = x[col].astype(int)\n",
    "    \n",
    "    # encoding labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    return x,y\n",
    "\n",
    "def data_encoding2(x,y):\n",
    "    def get_categorical_columns(df):\n",
    "        return list(df.select_dtypes(include=['object', 'category']).columns)\n",
    "    def get_numerical_columns(df):\n",
    "        return list(df.select_dtypes(include=['number']).columns)\n",
    "\n",
    "    categorical_columns = get_categorical_columns(x)\n",
    "    numerical_columns = get_numerical_columns(x)\n",
    "\n",
    "    # Clean categorical columns to remove duplicates and unexpected formats\n",
    "    def clean_categorical_columns(df, cat_columns):\n",
    "        cleaned_df = df.copy()\n",
    "        for col in cat_columns:\n",
    "            cleaned_df[col] = cleaned_df[col].apply(lambda x: str(x).strip())  # Strip leading/trailing spaces\n",
    "            cleaned_df[col] = cleaned_df[col].apply(lambda x: ' '.join(sorted(set(x.split()))))  # Remove duplicate words\n",
    "        return cleaned_df\n",
    "\n",
    "    def clean_target_variable(y):\n",
    "        cleaned_y = y.copy()\n",
    "        cleaned_y = cleaned_y.apply(lambda x: str(x).strip())  # Strip leading/trailing spaces\n",
    "        cleaned_y = cleaned_y.apply(lambda x: ' '.join(sorted(set(x.split()))))  # Remove duplicate words\n",
    "        return cleaned_y\n",
    "\n",
    "    x_cleaned = clean_categorical_columns(x, categorical_columns)\n",
    "    y_cleaned = clean_target_variable(y)\n",
    "\n",
    "    # Use LabelEncoder for encoding target variable\n",
    "    label_encoder_y = LabelEncoder()\n",
    "    y_encoded = label_encoder_y.fit_transform(y_cleaned)\n",
    "\n",
    "    encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "    x_encoded = encoder.fit_transform(x_cleaned, y_encoded)\n",
    "\n",
    "    return x_encoded, y_encoded\n",
    "\n",
    "def impute_missing_values_KNN(x):\n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    x.iloc[:,:] = imputer.fit_transform(x)\n",
    "    return x\n",
    "\n",
    "def data_upsampling(x, y):\n",
    "    # summarize distribution before upsampling\n",
    "    counter = Counter(y)\n",
    "    for k,v in counter.items():\n",
    "        per = v / len(y) * 100\n",
    "        print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    # plot the distribution\n",
    "    plt.bar(counter.keys(), counter.values())\n",
    "    plt.show()\n",
    "\n",
    "    oversample = SMOTE()\n",
    "    x, y = oversample.fit_resample(x, y)\n",
    "    # summarize distribution after upsampling\n",
    "    counter = Counter(y)\n",
    "    for k,v in counter.items():\n",
    "        per = v / len(y) * 100\n",
    "        print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    # plot the distribution\n",
    "    plt.bar(counter.keys(), counter.values())\n",
    "    plt.show()\n",
    "    return x,y\n",
    "\n",
    "def preprocess_data(x,y):\n",
    "    x,y = data_encoding2(x, y)\n",
    "    x = impute_missing_values_KNN(x)\n",
    "    # x,y = data_upsampling(x, y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded,y_train_encoded = preprocess_data(x_train,y_train)\n",
    "\n",
    "x_test_encoded,y_test_encoded = data_encoding2(x_test,y_test)\n",
    "x_test_encoded = impute_missing_values_KNN(x_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation f1-macro score:  0.6004017109394327\n",
      "Evaluation on Test data: \n",
      "accuracy = 0.3333333333333333\n",
      "precision = 0.4530655655655656\n",
      "recall = 0.34446882566585957\n",
      "f1-score = 0.2641341256366723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    # 'min_child_weight': [1, 3, 5],\n",
    "    # 'gamma': [0, 0.5, 1, 1.5],\n",
    "    'eta': [0.01, 0.1, 0.2],\n",
    "    # 'lambda': [0.01, 0.1, 1],\n",
    "    # 'alpha': [0, 0.1, 0.5, 1],\n",
    "    'max_depth': [3, 6, 9],\n",
    "}\n",
    "\n",
    "# Create a model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, objective='multi:softprob')\n",
    "# Create grid search object\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='f1_macro',n_jobs=4)\n",
    "# Fit the grid search object to the train data\n",
    "grid_search.fit(x_train_encoded, y_train_encoded)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"best params: \",best_params)\n",
    "\n",
    "# Cross-validation f1-macro score\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Cross-validation f1-macro score: \", best_score)\n",
    "\n",
    "# Refit the model with best hyperparameters to the train data\n",
    "best_xgb_model = XGBClassifier(**best_params, use_label_encoder=False, objective='multi:softprob')\n",
    "best_xgb_model.fit(x_train_encoded, y_train_encoded)\n",
    "\n",
    "# Predict labels of test data\n",
    "y_test_pred = best_xgb_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate performance metrics on Test Data\n",
    "accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "precision = precision_score(y_test_encoded, y_test_pred, average=\"macro\")\n",
    "recall = recall_score(y_test_encoded, y_test_pred, average=\"macro\")\n",
    "f1 = f1_score(y_test_encoded, y_test_pred, average=\"macro\")\n",
    "\n",
    "print(\"Evaluation on Test data: \")\n",
    "print(\"accuracy =\", accuracy)\n",
    "print(\"precision =\", precision)\n",
    "print(\"recall =\", recall)\n",
    "print(\"f1-score =\", f1)\n",
    "\n",
    "# Save the best model\n",
    "saveModel('best_xgb_model_main_5.pkl', best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve for the best model\n",
    "plot_learning_curves(best_xgb_model, x_train_encoded, y_train_encoded)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
